# -*- coding: utf-8 -*-
"""extender_regression4_rate

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1J2cyXRBlf9_0wLeik5Uu29QG4JibXR9Y
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error

### download
origin_data = [14.043, 15.507, 7.613, 12.3325,
               42.85, 46.27, 31.55, 5.95,
               43.88, 44.46, 43.72, 45.95,
               32.48, 33.75, 52.50, 46.49]

data1 = [10.32, 10.32, 11.96, 10.27,
         11.14, 7.54, 7.63, 7.01,
         11.56, 8.11, 6.1, 6.15,
         12.31, 9.45, 7.14, 8.31]

data2 = [12.12, 13.21, 15.22, 13.79,
         9.31, 10.23, 7.88, 5.37,
         9.27, 9.34, 8.59, 7.36,
         7.22, 6.52, 6.29, 4.53]

data3 = [8.04, 9.72, 8.00, 8.79,
         8.52, 9.25, 9.31, 9.48,
         7.63, 8.34, 11.53, 7.34,
         6.5, 8.85, 9.2, 7.18]

data4 = [12.87, 13.35, 13.39, 12.02,
         12.5, 12.94, 12.43, 11.52,
         13.35, 11.24, 10.75, 11.14,
         10.44, 9.81, 12.27, 14.15]

data6 = [7.68, 8.48, 9.84, 8.78,
         14.49, 10.24, 13.06, 9.99,
         11.70, 11.06, 11.71, 10.22,
         14.27, 11.34, 10.65, 4.54]

data7 = [12.05, 13.27, 13.79, 13.38,
         14.81, 15.87, 15.73, 15.31,
         14.10, 13.35, 14.71, 7.84,
         12.11, 14.14, 14.04, 10.54]

data10 = [15.57, 15.55, 15.59, 14.28,
         11.31, 15.34, 13.46, 13.35,
         11.89, 16.91, 13.76, 10.57,
         15.03, 13.76, 10.75, 7.59]

data11 = [11.06, 12.99, 15.76, 14.45,
         13.28, 14.01, 16.23, 15.83,
         10.18, 13.95, 11.90, 10.86,
         13.82, 15.11, 15.34, 7.15]

data13 = [11.21, 13.10, 13.92, 11.45,
         14.96, 14.49, 14.29, 15.29,
         14.27, 12.93, 11.59, 13.42,
         12.14, 9.13, 7.76, 8.48]

data16 = [5.71, 7.29, 10.30, 14.14,
          12.20, 11.61, 14.11, 14.34,
          8.17, 13.82, 15.26, 17.03,
          8.42, 12.04, 14.90, 18.54]

total_data = []
total_data.append(data1)
total_data.append(data2)
total_data.append(data3)
total_data.append(data4)
total_data.append(data6)
total_data.append(data7)
total_data.append(data10)
total_data.append(data11)
total_data.append(data13)
total_data.append(data16)

print(len(total_data))

print(total_data)

data = {
    'length' : [],
    'rate_of_rise' : []
}

df = pd.DataFrame(data) # 데이터프레임 생성

ROW = 4

for i in [0,1,2,3,5,6,9,10,12,15]:
    extender_x = int(i/ROW)
    extender_y = int(i%ROW)
    for j in range(len(total_data[int(i/5)])):
      now_x = int(j/ROW)
      now_y = int(j%ROW)
      length = ((extender_x-now_x)**2+(extender_y-now_y)**2)**(1/2)
      rate_of_rise = (total_data[int(i/5)][j]-origin_data[j])/origin_data[j]
      # 이상값 처리
      # if (rate_of_rise > 0):
      #     rate_of_rise = 0
      df.loc[len(df)] = [length, rate_of_rise]

print(df.head())

print(df)

# 독립 변수(X)와 종속 변수(y)를 정의
X = df[['length']]
y = df['rate_of_rise']

# 그래프 생성
plt.figure(figsize=(8, 6))
plt.scatter(X, y, label='data_point', color='b')
plt.title('the rate of increase over distance')
plt.xlabel('length')
plt.ylabel('rate_of_rise')
plt.legend()
plt.grid(True)
plt.plot(data['length'], data['rate_of_rise'])

# test
point = np.arange(0, 6)
plt.plot(point, point*((0.5-0.3)/(0-2))+0.5)

# 그래프 표시
plt.show()

# 학습 데이터와 테스트 데이터로 나눔
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)

# 선형 회귀 모델 생성 및 학습
model = LinearRegression()
model.fit(X_train, y_train)

# 테스트 데이터를 사용하여 모델 성능 평가 (MSE 계산)
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print(f'Mean Squared Error (MSE): {mse:.2f}')

# 평균 절대 오차 (MAE) 계산
mae = mean_absolute_error(y_test, y_pred)
print(f'Mean Absolute Error (MAE): {mae:.2f}')

# test_point_x = np.arange(0, 6)
test_point_x = np.linspace(0, 5, 100)
test_point_y = []

for i in test_point_x:
    predicted_slope = model.predict([[i]])
    test_point_y.append(predicted_slope[0])

plt.figure(figsize=(8, 6))
plt.scatter(X, y, label='data_point', color='b')
plt.title('the rate of increase over distance')
plt.xlabel('length')
plt.ylabel('rate_of_rise')
plt.legend()
plt.grid(True)

plt.plot(test_point_x, test_point_y)

plt.show()

# 특정 거리의 상승률 예측
specific_distance = 2  # 예측하려는 특정 거리
predicted_slope = model.predict([[specific_distance]])
print(f'{specific_distance} distance에서의 예상 rate_of_rise: {predicted_slope[0]:.2f}\n')

### previous code for reference ###
# test_point_x = np.linspace(0, 5, 100)
# test_point_y = []

# for i in test_point_x:
#     predicted_slope = model.predict([[i]])
#     test_point_y.append(predicted_slope)

#######################################################

# dataset recreate
recreated_data = []

df = pd.DataFrame(recreated_data) # 데이터프레임 생성

ROW = 4
TOTAL = 16

for i in range(TOTAL):
    # extender location
    extender_x = int(i/ROW)
    extender_y = int(i%ROW)
    temp_data = []
    for j in range(TOTAL):
        # now measure location
        now_x = int(j/ROW)
        now_y = int(j%ROW)

        # rate_of_rise 추출
        length = ((extender_x-now_x)**2+(extender_y-now_y)**2)**(1/2)
        predicted_slope = model.predict([[length]])
        print(i,j,length,predicted_slope)
        current_rate_of_rise = predicted_slope[0]

        temp_data.append(origin_data[j]+origin_data[j]*current_rate_of_rise)

    recreated_data.append(temp_data)
    temp_data = []

print(recreated_data)

print(recreated_data[6])

coor_x = np.arange(0, 16)


for i in [0, 5, 10, 15]:
    plt.subplot(2, 2, int(i/ROW) + 1)
    plt.scatter(coor_x, recreated_data[i], color='b', alpha=0.5)
    plt.scatter(coor_x, total_data[int(i/ROW)], color = 'r', alpha=0.5)
    plt.ylim(-5, 35)
    plt.legend(loc='upper right')
    plt.xlabel('Point')
    plt.ylabel('Speed')
    plt.tight_layout()
    plt.title(f'Point {i+1}')

plt.scatter(coor_x, origin_data, color='b', alpha=0.5)
plt.xlabel('Point')
plt.ylabel('Speed')
plt.title(f'Exclude Extender {i+1}')

coor_x = np.arange(0, 16)


for i in range(16):
    plt.subplot(4, 4, i + 1)
    plt.scatter(coor_x, recreated_data[i], color='b', alpha=0.5)
    plt.ylim(-5, 35)

# coor_x = np.arange(0, 16)
# coor_x2 = np.arange(0.5, 16)

# plt.figure(figsize=(12, 6))

# # 회귀 이후 다시 만든 데이터. blue
# # plt.subplot(1, 2, 1)
# for i in range(16):
#     plt.scatter(coor_x, recreated_data[i], color='b')

# # 처음 데이터. red
# # plt.subplot(1, 2, 2)
# for i in range(16):
#     plt.scatter(coor_x2, total_data[i], color = 'r')

# total_data에 대한 데이터 프레임 생성, index는 GPS좌표 대신 위치 특정을 위함, Dataset feature은 extender의 위치 특정
df_total = pd.DataFrame()

for i, data_set in enumerate(total_data, start=1):
    temp_df = pd.DataFrame({'wifi_speed': data_set})
    temp_df['GPS'] = range(1, len(temp_df) + 1)
    temp_df['Dataset'] = i
    df_total = pd.concat([df_total, temp_df], ignore_index=True)

# 각 데이터셋 별로 'wifi_speed' 열의 평균값과 최소값 계산
result_df_total = df_total.groupby('Dataset')['wifi_speed'].agg(['mean', 'min']).reset_index()
total_result_list = result_df_total[['mean', 'min']].values.tolist()

# recreated_data에 대한 데이터 프레임 생성, index는 GPS좌표 대신 위치 특정을 위함, Dataset feature은 extender의 위치 특정
df_recreated = pd.DataFrame()

for i, data_set in enumerate(recreated_data, start=1):
    temp_df = pd.DataFrame({'wifi_speed': data_set})
    temp_df['GPS'] = range(1, len(temp_df) + 1)
    temp_df['Dataset'] = i
    df_recreated = pd.concat([df_recreated, temp_df], ignore_index=True)

# 각 데이터셋 별로 'wifi_speed' 열의 평균값과 최소값 계산
result_df_recreated = df_recreated.groupby('Dataset')['wifi_speed'].agg(['mean', 'min']).reset_index()
recreated_result_list = result_df_recreated[['mean', 'min']].values.tolist()

# 생성된 데이터 프레임 확인
print(df_total)
print(df_recreated.head())

print(total_result_list)
print(recreated_result_list)

from sklearn.cluster import KMeans

# K-평균 클러스터링 모델 생성 및 적용 (wifi_speed 열만 사용)
k = 3  # 클러스터 개수 (원하는 개수로 설정)
kmeans = KMeans(n_clusters=k, random_state=0)
df_total['Cluster'] = kmeans.fit_predict(df_total[['wifi_speed']])

# 클러스터링 결과 시각화
plt.figure(figsize=(10, 6))

# 각 클러스터를 다른 색깔로 표시
markers = ['o', 's', '^']  # 원, 사각형, 삼각형 모양
colors = ['red', 'blue', 'green']

for cluster_id, marker, color in zip(range(k), markers, colors):
    cluster_subset = df_total[df_total['Cluster'] == cluster_id]
    plt.scatter(cluster_subset['wifi_speed'], cluster_subset['Dataset'], c=color, label=f'Cluster {cluster_id}', marker=marker, alpha=0.5)


plt.xlabel('wifi_speed')
plt.ylabel('Dataset')
plt.title('K-Means Clustering Results (wifi_speed, total)')
plt.legend()

plt.show()

# total_result 데이터 프레임을 생성하여 cluster 결과를 분석하여 저장하는 코드

# 'Cluster' 열이 2인 데이터 필터링
cluster_2_data = df_total[df_total['Cluster'] == 1]

# 각 Dataset에서 'Cluster' 2에 포함된 'wifi_speed'의 개수 계산
cluster_2_counts = cluster_2_data.groupby('Dataset')['wifi_speed'].count().reset_index()
cluster_2_counts.rename(columns={'wifi_speed': 'Cluster_2_Count'}, inplace=True)  # 열 이름 변경

# 각 Dataset을 모두 가져와서 'Cluster_2_Count'가 없는 경우에는 0으로 채우기
all_datasets = df_total['Dataset'].unique()
missing_datasets = set(all_datasets) - set(cluster_2_counts['Dataset'])
missing_counts = pd.DataFrame({'Dataset': list(missing_datasets), 'Cluster_2_Count': [0] * len(missing_datasets)})
cluster_2_counts = pd.concat([cluster_2_counts, missing_counts], ignore_index=True)

# 'cluster_2_counts' 데이터프레임을 개수가 작은 것부터 큰 것 순으로 정렬하여 등수 매기기
cluster_2_counts = cluster_2_counts.sort_values(by='Cluster_2_Count', ascending=True)
cluster_2_counts['Count_Rank'] = cluster_2_counts['Cluster_2_Count'].rank(method='min')
cluster_2_counts = cluster_2_counts.sort_values(by='Dataset', ascending=True)

# 각 Dataset에서 'Cluster' 2에 포함된 'wifi_speed'의 최소값 계산
cluster_2_min = cluster_2_data.groupby('Dataset')['wifi_speed'].min().reset_index()
cluster_2_min.rename(columns={'wifi_speed': 'Cluster_2_Min'}, inplace=True)  # 열 이름 변경

# 모든 Dataset을 가져와서 'Cluster_2_Min'이 없는 경우에는 최소값을 0으로 설정하고 누락된 데이터셋의 rank를 1로 설정
all_datasets = df_total['Dataset'].unique()
missing_datasets = set(all_datasets) - set(cluster_2_min['Dataset'])
missing_min = pd.DataFrame({'Dataset': list(missing_datasets), 'Cluster_2_Min': [0] * len(missing_datasets)})
cluster_2_min = pd.concat([cluster_2_min, missing_min], ignore_index=True)
cluster_2_min['Min_Rank'] = cluster_2_min['Cluster_2_Min'].rank(method='min')


# 각 Dataset에서 'wifi_speed'의 평균 계산
dataset_mean = df_total.groupby('Dataset')['wifi_speed'].mean().reset_index()
dataset_mean.rename(columns={'wifi_speed': 'Mean_wifi_speed'}, inplace=True)  # 열 이름 변경

# 'Mean_wifi_speed' 데이터프레임을 데이터프레임을 값이 큰 것 순으로 정렬하여 등수 매기기
dataset_mean = dataset_mean.sort_values(by='Mean_wifi_speed', ascending=False)
dataset_mean['Mean_Rank'] = range(1, len(dataset_mean) + 1)
cluster_2_counts = cluster_2_counts.sort_values(by='Dataset', ascending=True)

# 각 Dataset에서 'Cluster' 2에 포함된 'wifi_speed'의 평균 계산
#cluster_2_mean = cluster_2_data.groupby('Dataset')['wifi_speed'].mean().reset_index()
#cluster_2_mean.rename(columns={'wifi_speed': 'Cluster_2_Mean'}, inplace=True)

# 위 결과를 하나의 데이터프레임으로 합치기
total_result = pd.merge(cluster_2_counts, cluster_2_min, on='Dataset')
total_result = pd.merge(total_result, dataset_mean, on='Dataset')

# 결과 출력
print(total_result)

print(total_result[['Count_Rank', 'Min_Rank', 'Mean_Rank']])

COUNT_RANK = 0.3
MIN_RANK = 0.5
MEAN_RANK = 0.2

total_result['Product'] = total_result['Count_Rank']*COUNT_RANK + total_result['Min_Rank']*MIN_RANK + total_result['Mean_Rank']*MEAN_RANK

total_result_sorted = total_result.sort_values(by='Product')

print(total_result[['Count_Rank', 'Min_Rank', 'Mean_Rank', 'Product']])

print(total_result_sorted[['Count_Rank', 'Min_Rank', 'Mean_Rank', 'Product']])

df_recreated['Dataset'] = df_recreated['Dataset'].astype('category').cat.codes

# K-평균 클러스터링 모델 생성 및 적용 (wifi_speed 열만 사용)
k = 3  # 클러스터 개수 (원하는 개수로 설정)
kmeans = KMeans(n_clusters=k, random_state=0)
df_recreated['Cluster'] = kmeans.fit_predict(df_recreated[['wifi_speed']])

# 클러스터링 결과 시각화 (x축과 y축 바뀜)
plt.figure(figsize=(10, 6))

# 각 클러스터를 다른 색깔과 모양으로 표시
markers = ['o', 's', '^']  # 원, 사각형, 삼각형 모양
colors = ['red', 'blue', 'green']

for cluster_id, marker, color in zip(range(k), markers, colors):
    cluster_subset = df_recreated[df_recreated['Cluster'] == cluster_id]
    plt.scatter(cluster_subset['wifi_speed'], cluster_subset['Dataset'], c=color, label=f'Cluster {cluster_id}', marker=marker, alpha=0.5)

plt.xlabel('wifi_speed')
plt.ylabel('Dataset')
plt.title('K-Means Clustering Results (wifi_speed, recreated)')
plt.legend()

plt.show()

print(df_recreated)

# recreated_result 데이터 프레임을 생성하여 cluster 결과를 분석하여 저장하는 코드

# 'Cluster' 열이 2인 데이터 필터링
cluster_2_data = df_recreated[df_recreated['Cluster'] == 1]

# 각 Dataset에서 'Cluster' 2에 포함된 'wifi_speed'의 개수 계산
cluster_2_counts = cluster_2_data.groupby('Dataset')['wifi_speed'].count().reset_index()
cluster_2_counts.rename(columns={'wifi_speed': 'Cluster_1_Count'}, inplace=True)  # 열 이름 변경

# 'cluster_2_counts' 데이터프레임을 개수가 작은 것부터 큰 것 순으로 정렬하여 등수 매기기
cluster_2_counts = cluster_2_counts.sort_values(by='Cluster_1_Count', ascending=True)
cluster_2_counts['Count_Rank'] = cluster_2_counts['Cluster_1_Count'].rank(method='min')
cluster_2_counts = cluster_2_counts.sort_values(by='Dataset', ascending=True)

# 각 Dataset에서 'Cluster' 2에 포함된 'wifi_speed'의 최소값 계산
cluster_2_min = cluster_2_data.groupby('Dataset')['wifi_speed'].min().reset_index()
cluster_2_min.rename(columns={'wifi_speed': 'Cluster_1_Min'}, inplace=True)  # 열 이름 변경

# 'cluster_2_min' 데이터프레임을 데이터프레임을 값이 큰 것 순으로 정렬하여 등수 매기기
cluster_2_min = cluster_2_min.sort_values(by='Cluster_1_Min', ascending=False)
cluster_2_min['Min_Rank'] = cluster_2_min['Cluster_1_Min'].rank(ascending=False, method='min')
cluster_2_counts = cluster_2_counts.sort_values(by='Dataset', ascending=True)

# 각 Dataset에서 'wifi_speed'의 평균 계산
dataset_mean = df_recreated.groupby('Dataset')['wifi_speed'].mean().reset_index()
dataset_mean.rename(columns={'wifi_speed': 'Mean_wifi_speed'}, inplace=True)  # 열 이름 변경

# 'Mean_wifi_speed' 데이터프레임을 데이터프레임을 값이 큰 것 순으로 정렬하여 등수 매기기
dataset_mean = dataset_mean.sort_values(by='Mean_wifi_speed', ascending=False)
dataset_mean['Mean_Rank'] = range(1, len(dataset_mean) + 1)
cluster_2_counts = cluster_2_counts.sort_values(by='Dataset', ascending=True)

# 각 Dataset에서 'Cluster' 2에 포함된 'wifi_speed'의 평균 계산
#cluster_2_mean = cluster_2_data.groupby('Dataset')['wifi_speed'].mean().reset_index()
#cluster_2_mean.rename(columns={'wifi_speed': 'Cluster_2_Mean'}, inplace=True)

# 위 결과를 하나의 데이터프레임으로 합치기
recreated_result = pd.merge(cluster_2_counts, cluster_2_min, on='Dataset')
recreated_result = pd.merge(recreated_result, dataset_mean, on='Dataset')

# 결과 출력
print(recreated_result)

print(recreated_result[['Count_Rank', 'Min_Rank', 'Mean_Rank']])

COUNT_RANK = 0.3
MIN_RANK = 0.5
MEAN_RANK = 0.2

recreated_result['Product'] = recreated_result['Count_Rank']*COUNT_RANK + recreated_result['Min_Rank']*MIN_RANK + recreated_result['Mean_Rank']*MEAN_RANK

print(recreated_result[['Count_Rank', 'Min_Rank', 'Mean_Rank', 'Product']])

recreated_result_sorted = recreated_result.sort_values(by='Product')

print(recreated_result_sorted[['Count_Rank', 'Min_Rank', 'Mean_Rank', 'Product']])

import plotly.graph_objects as go
import plotly.subplots as sp

fig = sp.make_subplots(rows=4, cols=4)

for i in range(4):
    for j in range(4):
        trace = go.Heatmap(z=[recreated_data[(i+1)*(j+1)-1][a:a+4] for a in range(0, len(recreated_data), 4)], colorscale='YlOrRd')
        fig.add_trace(trace, row=i+1, col=j+1)

fig.show()

import plotly.subplots as sp

fig = sp.make_subplots(rows=4, cols=4)

print(len(total_data))
print(len(total_data[0]))
print(total_data)

for i in range(4):
    for j in range(4):
        if((i*4)+j>9 or (i*4)+j<0):break
        trace = go.Heatmap(z=[total_data[(i*4)+j][a:a+4] for a in range(0, 16, 4)], colorscale='YlOrRd')
        fig.add_trace(trace, row=i+1, col=j+1)

fig.show()

# 데이터를 4x4 행렬로 재구성
data_matrix = [origin_data[i:i+4] for i in range(0, len(origin_data), 4)]

# 히트맵 생성
heatmap = go.Heatmap(z=data_matrix, colorscale='YlOrRd', text=data_matrix)

# 레이아웃 설정
layout = go.Layout(title='Heatmap', xaxis=dict(title='X-axis'), yaxis=dict(title='Y-axis'))

# 그래프 출력
fig = go.Figure(data=[heatmap], layout=layout)
fig.show()
